{"componentChunkName":"component---src-pages-markdown-remark-frontmatter-slug-js","path":"/methodology/","result":{"data":{"markdownRemark":{"html":"<h1 id=\"methodology\">Methodology</h1>\n<h2 id=\"data\">Data</h2>\n<p>Our Segformer model underwent training utilizing the dataset provided by\nMindboggle-101 via their open science framework <a href=\"#references\">[3]</a>. This dataset comprises\nT1-weighted MRI images, along with man-made volumetric labels that\ncorrespond to distinct cerebral regions. Subsequently, the Segformer\nmodel was subjected to testing using patient data sourced from the\nParkinson’s Progression Markers Initiative (PPMI) database <a href=\"#references\">[4]</a>. This\npatient dataset includes T1-weighted MRI images, DaTSCAN SPECT images,\nand comprehensive baseline cohort information for each patient. The\nimage pre-processing workflow for both training and testing phases of\nour model is elucidated in Figure 2. Regarding the Mindboggle MRI data,\nthese images were already skull stripped and conformed to the Montreal\nNeurological Institute (MNI) coordinate system. Subsequently, a Z-score\nnormalization technique was applied to standardize pixel value\ndistributions.</p>\n<p><strong>Z-score Normalization</strong> is a technique that scales the values of a\nfeature to have a mean of 0 and a standard deviation of 1. This initial\nstep is crucial to standardize all MRI images which were taken across\nvarious systems. The formula for Z-score normalization of a pixel, <em>x</em>,\nis:</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><msub><mi>x</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{align*}\nx_{new} = \\frac{x-\\mu}{\\sigma}\n\\end{align*}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.2463em;vertical-align:-0.8732em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3732em;\"><span style=\"top:-3.3732em;\"><span class=\"pstrut\" style=\"height:3.2603em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2603em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8732em;\"><span></span></span></span></span></span></span></span></span></span></span></span></div>\n<p>where <em>x</em><sub><em>n<strong>e</strong>w</em></sub> is the new value for the pixel, <em>μ</em> is the\naverage value of the MRI, and <em>σ</em> is the standard deviation of the\nMRI.</p>\n<p><strong>Absolute discretization</strong> is a preprocessing technique that takes in\nan MRI with a continuous range of values and assigns each pixel to a\ndiscrete bin, where the number of bins is predefined. Literature has\nshown that absolute discretization boosts radiomic feature extraction\nfor MRI images <a href=\"#references\">[1]</a>. For the Segformer preprocessing, a bin size of 256 was\nused to cover the range of grayscale. The formula for absolute\ndiscretization is below:</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><msub><mi>x</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mn>256</mn><mo>∗</mo><mfrac><mrow><mi>x</mi><mo>−</mo><msub><mi>x</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mrow><msub><mi>x</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>−</mo><msub><mi>x</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{align*}\nx_{new} = 256 * \\frac{x-x_{min}}{x_{max}-x_{min}}\n\\end{align*}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.3963em;vertical-align:-0.9482em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.4482em;\"><span style=\"top:-3.4482em;\"><span class=\"pstrut\" style=\"height:3.2603em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">256</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2603em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">ma</span><span class=\"mord mathnormal mtight\">x</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">min</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">min</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.836em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9482em;\"><span></span></span></span></span></span></span></span></span></span></span></span></div>\n<p>then <em>x</em><sub><em>n<strong>e</strong>w</em></sub> is converted into an integer, assigning it\nto a bin.</p>\n<p><strong>Gaussian noise</strong> was introduced to the MRI images to add a controlled\nlevel of real-world noise. Upon observation, the Mindboggle dataset was\ncleaner than its PPMI counterpart. Since the weights trained off of\nMindboggle are applied to PPMI for segmentation, the noise was added to\nbring the two datasets more in line and allow the Segformer model to\naccount for noisy inputs. The formula for adding Gaussian noise is\nbelow:</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mtable rowspacing=\"0.25em\" columnalign=\"right\" columnspacing=\"\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><msub><mi>x</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mtext> </mtext><mi>x</mi><mtext> </mtext><mo>+</mo><mtext> </mtext><mi>𝒩</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding=\"application/x-tex\">\\begin{align*}\nx_{new} = x + 𝒩(0,3)\n\\end{align*}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5em;vertical-align:-0.5em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1em;\"><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\"> </span><span class=\"mord mathnormal\">x</span><span class=\"mord\"> </span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\"> </span><span class=\"mord mathscr\" style=\"margin-right:0.3525em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5em;\"><span></span></span></span></span></span></span></span></span></span></span></span></div>\n<p>These 3D volumetric images were then converted into 2D slices in the\naxial, sagittal, and coronal planes, facilitating their input into the\nSegformer model for training.</p>\n<p><strong>Skull-stripping</strong> of the PPMI MRI images were done using the Robex\npackage <a href=\"#references\">[2]</a>. The Robex method combines a Random Forest classifier to detect\nthe brain-skull boundary and a point distribution model to guarantee the\nresult is possible.</p>\n<p><strong>The MNI Coordinate System</strong> is a commonly used coordinate system for\nbrain MRI analysis and the one used by PPMI for their DaTSCAN images.\nEach coordinate in the MNI system aligns to a specific location in the\nbrain. The coordinate (0,0,0) lies center in the brain with the right\nhemisphere, front of brain, and top of brain being the positive\ndirection for the x, y, and z axis respectively.</p>\n<p>MRI template using an affine transformation. Following alignment, the\nMRI images were subjected to Z-score normalization and absolute\ndiscretization to ensure alignment with the training data. They were\nthen segmented into 2D slices within the axial, sagittal, and coronal\nplanes before being incorporated into the model.</p>\n<p>For DaTSCAN images, they were matched with MRI images taken at the\nclosest time point within a year. These DaTSCAN images were already\naligned with the MNI coordinate system but were upscaled to match the\ndimensions of the MRI images, resulting in a uniform size of (182, 218,\n182). Each image pair was subsequently assigned a patient state label\nusing information from PPMI’s CONCOHORT section.</p>\n<h2 id=\"segformer\">Segformer</h2>\n<p>The segmentation of the MRI images was conducted using a transformer based semantic segmentation model known as Segformer by Xie et.al. <a href=\"#references\">[5]</a>. Segformer differs from other transformer based segmentation models through its unique hierarchical encoder and multilayer perceptron (MLP) decoder. The hierarchical encoder utilizes 4x4 patch sizes which allows for the generation of both fine and course level features at 1/4, 1/8, 1/16, and 1/32 the original resolution. The MLP decoder then combines the information from all resolution levels into quick and accurate results. Semantic segmentation is the classification of individual pixels into a specific category. We utilized this model to assign each pixel of the MRI to one of 62 labels provided by the Desikan-Killiany-Tourville cortical labeling protocol <a href=\"#references\">[3]</a>. The left and right caudate and putamen are the regions of the brain that can be used to overlay onto the DaTSCAN images and extract the SBR ratio. To utilize the model for the 3D MRI's, the MRI's were sliced into 2D images across the coronal, saggital, and axial planes. The 2D images were then loaded into the model with an output being a 2D matrix of the same size of the MRI slice with the values being the assigned labels to the pixels.</p>\n<figure id='analysis'>\n    <span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; '>\n      <a class='gatsby-resp-image-link' href='/static/073c6d4a69b25afee9bdc898e132995a/f098e/analysis.png' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 59.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB/ElEQVR42nVT2XKbQBDk/38keUlSecnxkFQpjispjG4ZIUAIJEeyEAhxrFgQ0JldHVbseKq2dnZnpqd7DwVX5jgOur0+7rQ2TNOWe3VdyyHsUNXgxQEHWlq2DU3T4Loe6qZBeajkrKRpijhJZMFyk+HLzRifWvfSPwNW1RHQWSZotT2ouo/HIEaa7LD0d2hpLr5S3cJnUK4Z7POcOjuSXZ7zFwyjaAfTsuF6cxRFIfc4zaN7HVq7gzhOoIgA58dixjIMBn30ej1k2TXDSvpBEFCsC5vklmV5OqgGjHLjOEYjJGenhbCEpI/HY+i6Lv3nDMMwhKreYTKZXAFCst3v99JXzptpmuFxvZaHbVoW/M0GjJJE1yfJEYbDoby8VwFFgTDPMWGNR/BmNuYzC1PLwIPnyJiQLAA21KTT6dAZmxLg3OgfwITkpoyjDF1wf4o88FCQn5NfBLML4Gg4gDf3MBoNsVjMYRgG1qToVYbL7md4t28x//0Of9T3NNNQP5LsHME2QuS0UbId+MpExYjEwwg8CY6AdKkvzrDIIvB4Q0kheBoip2Sebk/3SCwpviDWfaMFfaZh67soCaSiVy4ukDF2BBTI58Vr1uCowlrpUKe/oFo3cFZTGLZBD3xJKtjlaSlPVc3/x/O4+IJ1iZ/6N3z48Qa3xneUVXFJ+wvZlpBzjdjQFwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='Analysis Process Flowchart' title='' src='/static/073c6d4a69b25afee9bdc898e132995a/5a190/analysis.png' srcset='/static/073c6d4a69b25afee9bdc898e132995a/772e8/analysis.png 200w,\n/static/073c6d4a69b25afee9bdc898e132995a/e17e5/analysis.png 400w,\n/static/073c6d4a69b25afee9bdc898e132995a/5a190/analysis.png 800w,\n/static/073c6d4a69b25afee9bdc898e132995a/c1b63/analysis.png 1200w,\n/static/073c6d4a69b25afee9bdc898e132995a/f098e/analysis.png 1506w' sizes='(max-width: 800px) 100vw, 800px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy' decoding='async'>\n  </a>\n    </span>\n    <figcaption>Figure 1: Analysis Process Flowchart.</figcaption>\n</figure>\n<figure id='3images'>\n    <span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; '>\n      <a class='gatsby-resp-image-link' href='/static/db92ab562535ae99e00c5f3b3602ecc1/9de76/3Images.png' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 41%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAACI0lEQVR42j2S3U9ScRjHfyXaZm6tcm05epmt1ubBowJyOHAOmIqQRPkGMhXwLQw1VN5ClKyWW6uLtMxFI7rysrkx/75PBy66+G7Pc/PZ9/t8H5FOp1EUBV3X8Xg8uFwuNF1jc+01i/6XRPQFot44s56YMcdI+Jc4SP4iNfqT7GiFoq9KcazKkuuYr8U6wu12I4RowoLBIBbJ0twVm8rdtkd0m3oYuRfE0+XngUnCfOU+43IGt8gyLvL4xRsmW4rYRYoV33eE0+lElmUqlQqHh4dUq1XMd8wM9jmwXLUTVRK8CmXJRnLMOZd53G5hYaDMjHjHasceO7cLbN4oERAF8oEqohE1HA5zdnbG0dERtd81XG4XA5IVR+cQqWcb5BMFthJFlsbT9F8fJNG7R0R84JNrkWPPAh+1dYKG29JYDTE8PEy5XKZer1Or1Tg/PycyGzGANka6g2Sn9shNldiZ3GdrYhdnl06sp8S84TDZXmDVtMv6tRIvRI6y7w+iUUgqleLi4qIZueF06Im3CVRueZvAdKjAxtMMa6Nb9N8cJCbvM3/pPbHLZeItb1luOzBOUKDkNxyqqkprayuZTIZ8Pk8gEPhfitn0EHunxpyyzERvFKnD3iwlJOfwGhEnDE0boEYpithgzXeCSCaTSJKEw+FA0zSsVityv8xKfJWoHidkm2FanWvquS1svM88xdgPEuo31tUTttVT0u5Ton1f+Lz9l3/HmTix07NezAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='Overview of Segformer Process' title='' src='/static/db92ab562535ae99e00c5f3b3602ecc1/5a190/3Images.png' srcset='/static/db92ab562535ae99e00c5f3b3602ecc1/772e8/3Images.png 200w,\n/static/db92ab562535ae99e00c5f3b3602ecc1/e17e5/3Images.png 400w,\n/static/db92ab562535ae99e00c5f3b3602ecc1/5a190/3Images.png 800w,\n/static/db92ab562535ae99e00c5f3b3602ecc1/c1b63/3Images.png 1200w,\n/static/db92ab562535ae99e00c5f3b3602ecc1/9de76/3Images.png 1423w' sizes='(max-width: 800px) 100vw, 800px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy' decoding='async'>\n  </a>\n    </span>\n    <figcaption>Figure 2: Overview of Segformer Process. a) T1-Weighted MRI b) Mask generated from Segformer overlaid on MRI c) Mask generated from Segformer overlaid on DaTSCAN.</figcaption>\n</figure>\n<h3 id=\"references\">References</h3>\n<ol>\n<li>Loïc Duron, Daniel Balvay, Saskia Vande Perre, Afef Bou- chouicha, Julien Savatovsky, Jean-Claude Sadik, Isabelle Thomassin-Naggara, Laure Fournier, and Augustin Lecler. Gray-level discretization impacts reproducible mri radiomics texture features. PLOS ONE, 14(3):1–14, 03 2019.</li>\n<li>Juan Eugenio Iglesias, Cheng-Yi Liu, Paul M Thompson, and Zhuowen Tu. Robust brain extraction across datasets and comparison with publicly available methods. IEEE transac- tions on medical imaging, 30(9):1617–1634, 2011.</li>\n<li>Arno Klein and Jason Tourville. 101 labeled brain images and a consistent human cortical labeling protocol. Frontiers in Neuroscience, 6, 2012.</li>\n<li>T. Marek K. Jennings D. Lasch S. Siderowf A. Tanner C. Simuni. Parkinson progression marker initiative. Progress in neurobiology, pages 629–635, 2011.</li>\n<li>Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, 270 Jose ́M.A ́lvarez,andPingLuo.Segformer:Simpleandef- 271 ficient design for semantic segmentation with transformers. 272 CoRR, abs/2105.15203, 2021</li>\n</ol>","frontmatter":{"title":"Methodology"}}},"pageContext":{"id":"32799003-9666-5d95-ab63-e57cb114f7ec","frontmatter__slug":"/methodology","__params":{"frontmatter__slug":"methodology"}}},"staticQueryHashes":["429448491"],"slicesMap":{}}